{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d2a5848-d11c-46f6-9898-18a17274f83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, IntSlider, Dropdown\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "# File path - update this\n",
    "filename = \"/home/kronberger/Downloads/LineDataNewNew128.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94d11d76-572b-4380-a891-d924379885f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "EXPLORING: /home/kronberger/Downloads/LineDataNewNew128.mat\n",
      "==================================================\n",
      "\n",
      "üìä x_raw\n",
      "   Shape: (128, 2423296)\n",
      "   Type: float64\n",
      "   Size: 2366.5 MB\n",
      "   ‚ö†Ô∏è  Large dataset - use slicing for exploration\n",
      "\n",
      "üìä y\n",
      "   Shape: (6, 2423296)\n",
      "   Type: float64\n",
      "   Size: 110.9 MB\n",
      "   ‚ö†Ô∏è  Large dataset - use slicing for exploration\n",
      "\n",
      "üìà SUMMARY:\n",
      "   Total datasets: 2\n",
      "   Total size: 2477.4 MB\n"
     ]
    }
   ],
   "source": [
    "def explore_structure_safe(filename):\n",
    "    \"\"\"Explore file structure without loading large arrays\"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"EXPLORING: {filename}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    datasets_info = {}\n",
    "    \n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        def collect_info_safe(name, obj):\n",
    "            if isinstance(obj, h5py.Dataset):\n",
    "                # Don't load data, just get metadata\n",
    "                shape = obj.shape\n",
    "                dtype = obj.dtype\n",
    "                size_mb = np.prod(shape) * dtype.itemsize / (1024**2)\n",
    "                \n",
    "                datasets_info[name] = {\n",
    "                    'shape': shape,\n",
    "                    'dtype': str(dtype),\n",
    "                    'size_mb': size_mb,\n",
    "                    'dataset_obj': obj  # Keep reference for later use\n",
    "                }\n",
    "                \n",
    "                print(f\"\\nüìä {name}\")\n",
    "                print(f\"   Shape: {shape}\")\n",
    "                print(f\"   Type: {dtype}\")\n",
    "                print(f\"   Size: {size_mb:.1f} MB\")\n",
    "                \n",
    "                # Interpret shapes for STM/AFM data\n",
    "                if len(shape) == 2 and shape[0] == shape[1]:\n",
    "                    print(f\"   üñºÔ∏è  Single {shape[0]}√ó{shape[1]} image/map\")\n",
    "                elif len(shape) == 3:\n",
    "                    if shape[0] == shape[1]:  # spatial dimensions equal\n",
    "                        print(f\"   üìö Stack of {shape[2]} images, each {shape[0]}√ó{shape[1]} pixels\")\n",
    "                    else:\n",
    "                        print(f\"   üìä 3D data: {shape}\")\n",
    "                elif len(shape) == 4:\n",
    "                    print(f\"   üóÇÔ∏è  4D dataset (possibly multiple channels/conditions): {shape}\")\n",
    "                \n",
    "                # Warn about large datasets\n",
    "                if size_mb > 100:\n",
    "                    print(f\"   ‚ö†Ô∏è  Large dataset - use slicing for exploration\")\n",
    "        \n",
    "        f.visititems(collect_info_safe)\n",
    "        \n",
    "    total_size = sum(info['size_mb'] for info in datasets_info.values())\n",
    "    print(f\"\\nüìà SUMMARY:\")\n",
    "    print(f\"   Total datasets: {len(datasets_info)}\")\n",
    "    print(f\"   Total size: {total_size:.1f} MB\")\n",
    "    \n",
    "    return datasets_info\n",
    "\n",
    "# Run safe exploration\n",
    "datasets_info = explore_structure_safe(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb8b365-df1b-4c2e-898f-acc1296f669f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Previewing: x_raw\n"
     ]
    }
   ],
   "source": [
    "def sample_large_dataset(dataset_obj, max_samples=5):\n",
    "    \"\"\"Sample a few slices from large datasets\"\"\"\n",
    "    shape = dataset_obj.shape\n",
    "    \n",
    "    if len(shape) == 2:\n",
    "        # Single 2D image - just return it\n",
    "        return dataset_obj[:]\n",
    "    elif len(shape) == 3:\n",
    "        # Multiple images - sample a few\n",
    "        n_images = shape[2]\n",
    "        if n_images <= max_samples:\n",
    "            indices = list(range(n_images))\n",
    "        else:\n",
    "            # Sample evenly distributed indices\n",
    "            indices = np.linspace(0, n_images-1, max_samples, dtype=int)\n",
    "        \n",
    "        samples = {}\n",
    "        for i, idx in enumerate(indices):\n",
    "            samples[f\"slice_{idx}\"] = dataset_obj[:, :, idx]\n",
    "        return samples\n",
    "    elif len(shape) == 4:\n",
    "        # 4D data - sample from last dimension\n",
    "        n_slices = shape[3]\n",
    "        if n_slices <= max_samples:\n",
    "            indices = list(range(n_slices))\n",
    "        else:\n",
    "            indices = np.linspace(0, n_slices-1, max_samples, dtype=int)\n",
    "        \n",
    "        samples = {}\n",
    "        for i, idx in enumerate(indices):\n",
    "            samples[f\"slice_{idx}\"] = dataset_obj[:, :, :, idx]\n",
    "        return samples\n",
    "    else:\n",
    "        print(f\"Unsupported shape: {shape}\")\n",
    "        return None\n",
    "\n",
    "def quick_preview(datasets_info):\n",
    "    \"\"\"Show quick previews of datasets\"\"\"\n",
    "    \n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        for name, info in datasets_info.items():\n",
    "            print(f\"\\nüîç Previewing: {name}\")\n",
    "            dataset_obj = f[name]\n",
    "            \n",
    "            # Sample data safely\n",
    "            samples = sample_large_dataset(dataset_obj, max_samples=3)\n",
    "            \n",
    "            if samples is None:\n",
    "                continue\n",
    "            \n",
    "            if isinstance(samples, dict):\n",
    "                # Multiple samples\n",
    "                n_samples = len(samples)\n",
    "                fig, axes = plt.subplots(1, n_samples, figsize=(4*n_samples, 4))\n",
    "                if n_samples == 1:\n",
    "                    axes = [axes]\n",
    "                \n",
    "                for i, (slice_name, data) in enumerate(samples.items()):\n",
    "                    if len(data.shape) == 2:\n",
    "                        im = axes[i].imshow(data, cmap='viridis', aspect='auto')\n",
    "                        axes[i].set_title(f\"{name}\\n{slice_name}\")\n",
    "                        plt.colorbar(im, ax=axes[i], shrink=0.8)\n",
    "                    else:\n",
    "                        # If still 3D, take middle slice\n",
    "                        middle = data.shape[2] // 2\n",
    "                        im = axes[i].imshow(data[:, :, middle], cmap='viridis', aspect='auto')\n",
    "                        axes[i].set_title(f\"{name}\\n{slice_name}_mid\")\n",
    "                        plt.colorbar(im, ax=axes[i], shrink=0.8)\n",
    "                \n",
    "            else:\n",
    "                # Single sample\n",
    "                fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "                im = ax.imshow(samples, cmap='viridis', aspect='auto')\n",
    "                ax.set_title(f\"{name}\")\n",
    "                plt.colorbar(im, ax=ax)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "# Preview datasets\n",
    "quick_preview(datasets_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3d5389-1968-4f20-8cd2-5c8e2021d5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_slice_explorer(datasets_info):\n",
    "    \"\"\"Create interactive explorer for image stacks\"\"\"\n",
    "    \n",
    "    dataset_names = [name for name, info in datasets_info.items() \n",
    "                    if len(info['shape']) >= 3]\n",
    "    \n",
    "    if not dataset_names:\n",
    "        print(\"No multi-dimensional datasets found for slicing\")\n",
    "        return\n",
    "    \n",
    "    @interact(\n",
    "        dataset=Dropdown(options=dataset_names, description='Dataset:'),\n",
    "        colormap=Dropdown(options=['viridis', 'hot', 'cool', 'plasma', 'gray'], \n",
    "                         value='viridis', description='Colormap:')\n",
    "    )\n",
    "    def explore_slices(dataset, colormap):\n",
    "        info = datasets_info[dataset]\n",
    "        print(f\"üìä Dataset: {dataset}\")\n",
    "        print(f\"   Shape: {info['shape']}\")\n",
    "        print(f\"   Size: {info['size_mb']:.1f} MB\")\n",
    "        \n",
    "        with h5py.File(filename, 'r') as f:\n",
    "            dataset_obj = f[dataset]\n",
    "            shape = dataset_obj.shape\n",
    "            \n",
    "            if len(shape) == 3:\n",
    "                max_slice = shape[2] - 1\n",
    "                \n",
    "                @interact(slice_idx=IntSlider(min=0, max=max_slice, step=1, value=0))\n",
    "                def show_slice(slice_idx):\n",
    "                    # Load only one slice at a time\n",
    "                    data_slice = dataset_obj[:, :, slice_idx]\n",
    "                    \n",
    "                    plt.figure(figsize=(8, 8))\n",
    "                    im = plt.imshow(data_slice, cmap=colormap, aspect='auto')\n",
    "                    plt.colorbar(im)\n",
    "                    plt.title(f\"{dataset} - Slice {slice_idx}/{max_slice}\")\n",
    "                    \n",
    "                    # Add statistics\n",
    "                    flat = data_slice.flatten()\n",
    "                    plt.figtext(0.02, 0.02, \n",
    "                              f\"Min: {np.min(flat):.3e}, Max: {np.max(flat):.3e}, Mean: {np.mean(flat):.3e}\",\n",
    "                              fontsize=8)\n",
    "                    plt.show()\n",
    "                    \n",
    "            elif len(shape) == 4:\n",
    "                max_slice = shape[3] - 1\n",
    "                \n",
    "                @interact(slice_idx=IntSlider(min=0, max=max_slice, step=1, value=0))\n",
    "                def show_4d_slice(slice_idx):\n",
    "                    # For 4D, show middle of third dimension\n",
    "                    mid_3d = shape[2] // 2\n",
    "                    data_slice = dataset_obj[:, :, mid_3d, slice_idx]\n",
    "                    \n",
    "                    plt.figure(figsize=(8, 8))\n",
    "                    im = plt.imshow(data_slice, cmap=colormap, aspect='auto')\n",
    "                    plt.colorbar(im)\n",
    "                    plt.title(f\"{dataset} - 4D Slice {slice_idx}/{max_slice}\")\n",
    "                    plt.show()\n",
    "\n",
    "create_slice_explorer(datasets_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ada460e-38de-4cbf-938d-dc801d5515c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_selected_slices(datasets_info, export_dir=\"./exported_data\"):\n",
    "    \"\"\"Export only selected slices to avoid memory issues\"\"\"\n",
    "    import os\n",
    "    import json\n",
    "    \n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "    \n",
    "    metadata = {}\n",
    "    \n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        for name, info in datasets_info.items():\n",
    "            dataset_obj = f[name]\n",
    "            shape = dataset_obj.shape\n",
    "            \n",
    "            safe_name = name.replace('/', '_').replace(' ', '_')\n",
    "            \n",
    "            if len(shape) == 2:\n",
    "                # Single image - export directly\n",
    "                np.save(os.path.join(export_dir, f\"{safe_name}.npy\"), dataset_obj[:])\n",
    "                metadata[name] = {\n",
    "                    'filename': f\"{safe_name}.npy\",\n",
    "                    'type': 'single_image',\n",
    "                    'shape': shape\n",
    "                }\n",
    "                print(f\"‚úÖ Exported single image: {name}\")\n",
    "                \n",
    "            elif len(shape) >= 3:\n",
    "                # Export first, middle, and last slices\n",
    "                n_slices = shape[-1]\n",
    "                export_indices = [0, n_slices//2, n_slices-1]\n",
    "                \n",
    "                for i, slice_idx in enumerate(export_indices):\n",
    "                    if len(shape) == 3:\n",
    "                        slice_data = dataset_obj[:, :, slice_idx]\n",
    "                    elif len(shape) == 4:\n",
    "                        slice_data = dataset_obj[:, :, 0, slice_idx]\n",
    "                    \n",
    "                    filename_slice = f\"{safe_name}_slice_{slice_idx}.npy\"\n",
    "                    np.save(os.path.join(export_dir, filename_slice), slice_data)\n",
    "                    \n",
    "                    metadata[f\"{name}_slice_{slice_idx}\"] = {\n",
    "                        'filename': filename_slice,\n",
    "                        'type': 'image_slice',\n",
    "                        'original_shape': shape,\n",
    "                        'slice_index': slice_idx,\n",
    "                        'slice_shape': slice_data.shape\n",
    "                    }\n",
    "                \n",
    "                print(f\"‚úÖ Exported 3 slices from: {name}\")\n",
    "    \n",
    "    # Save metadata\n",
    "    with open(os.path.join(export_dir, 'metadata.json'), 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nüìÅ Selected data exported to: {export_dir}\")\n",
    "\n",
    "# Uncomment to export sample slices\n",
    "# export_selected_slices(datasets_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
